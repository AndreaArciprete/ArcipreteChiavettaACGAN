{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ACGAN_MNIST_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a9ef659cc5f46519e203509fe91990f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da7b036040b54ec387a54cf9d024498a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5a5b4ff6e8444dceb61e88f5e6c2db71",
              "IPY_MODEL_456994c63d594cd19922029715d65bb0"
            ]
          }
        },
        "da7b036040b54ec387a54cf9d024498a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a5b4ff6e8444dceb61e88f5e6c2db71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b887f592db524055a7bb4a066602fd6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03b877a23b4b4b5a9768c712fb9e1b8d"
          }
        },
        "456994c63d594cd19922029715d65bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b4ee9a4e582441ba031fb2650bc6fc1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [11:50&lt;00:00, 13962.30it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47f53791513a455ca72cd7c454329988"
          }
        },
        "b887f592db524055a7bb4a066602fd6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03b877a23b4b4b5a9768c712fb9e1b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b4ee9a4e582441ba031fb2650bc6fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47f53791513a455ca72cd7c454329988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "830abced7fd84ff88300bdc9ef47486a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_67c466fd0ac1455babde1389c24d7988",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a5e1721e2f44e1dadf917bfdc6e972b",
              "IPY_MODEL_9eaf918b17f847e99ba19fdf86ddd4e0"
            ]
          }
        },
        "67c466fd0ac1455babde1389c24d7988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a5e1721e2f44e1dadf917bfdc6e972b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_977035f38554459ba01abd3dbe1f086e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8edf01ce67d74664b6d917c75d064806"
          }
        },
        "9eaf918b17f847e99ba19fdf86ddd4e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f56e8ff3ebe4ecab88fab083a2500be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:44&lt;00:00, 667.36it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c2a834f7a4f4070921b383381cd9a9c"
          }
        },
        "977035f38554459ba01abd3dbe1f086e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8edf01ce67d74664b6d917c75d064806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f56e8ff3ebe4ecab88fab083a2500be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c2a834f7a4f4070921b383381cd9a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed8390729a094d97b91724d0a56aac9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65b732ce0f074c1fbaa21207ba6fcae0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31059661c0744addbee994262084b1b7",
              "IPY_MODEL_a727a3e88f9f4fbb95c48d714e9c5bf4"
            ]
          }
        },
        "65b732ce0f074c1fbaa21207ba6fcae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31059661c0744addbee994262084b1b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6b12a4dfb5e6449587a83ee6923b5ea7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad03af148bdf46718d9bfde1ab1befbc"
          }
        },
        "a727a3e88f9f4fbb95c48d714e9c5bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0af765dad10848f59fb5eb8d12b0d153",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:44&lt;00:00, 37276.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27c5c30395854a9bbe731267c9c76856"
          }
        },
        "6b12a4dfb5e6449587a83ee6923b5ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad03af148bdf46718d9bfde1ab1befbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0af765dad10848f59fb5eb8d12b0d153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27c5c30395854a9bbe731267c9c76856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb68a61ba71a4b4780e60f7ab522815e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18337ec894ba4572a9b5d2db9e13aea5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6305b647030e47c58434bc0b1c8e10dd",
              "IPY_MODEL_c6ecbf7d81214a8280c721b860374662"
            ]
          }
        },
        "18337ec894ba4572a9b5d2db9e13aea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6305b647030e47c58434bc0b1c8e10dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25295284634f476bbc1dc02921f195c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a51dd915ded4f7cb22901986e79bec6"
          }
        },
        "c6ecbf7d81214a8280c721b860374662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7604dd524e7e4901bf0217431eaa9db9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 24641.12it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e895cec77b00423db0b4330ddc93b199"
          }
        },
        "25295284634f476bbc1dc02921f195c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a51dd915ded4f7cb22901986e79bec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7604dd524e7e4901bf0217431eaa9db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e895cec77b00423db0b4330ddc93b199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE8v1l6Z1rVZ"
      },
      "source": [
        "#Import librerie di cui necessitiamo\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm97zOg02CDv"
      },
      "source": [
        "\"\"\"Creiamo una directory in cui andremo a salvare tutte le immagini che man mano\n",
        "verranno generate in fase di training del modello per valutare quanto il modello\n",
        "sta funzionando bene\"\"\"\n",
        "os.makedirs(\"results_images\", exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4mEhiFx2p_P",
        "outputId": "d8f2f69c-b0ca-4739-a047-721df8b1e26e"
      },
      "source": [
        "\"\"\"Sfruttando la libreria argparse creiamo una sorta di namespace contenente\n",
        "tutte le variabili che ci serviranno da ora in avanti\"\"\"\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('-f')\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=260, help=\"number of epochs of training\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
        "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
        "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=4, help=\"number of cpu threads to use during batch generation\")\n",
        "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
        "parser.add_argument(\"--n_classes\", type=int, default=10, help=\"number of classes for dataset\")\n",
        "parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\n",
        "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
        "parser.add_argument(\"--sample_interval\", type=int, default=10, help=\"interval between image sampling\")\n",
        "opt = parser.parse_args()\n",
        "print(opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(b1=0.5, b2=0.999, batch_size=64, channels=1, f='/root/.local/share/jupyter/runtime/kernel-649541b3-32d9-49e0-a4ac-a49a946c52a2.json', img_size=32, latent_dim=100, lr=0.0002, n_classes=10, n_cpu=4, n_epochs=260, sample_interval=10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z1BWBDM32bP"
      },
      "source": [
        "\"\"\"Al reference cuda assegniamo True se la GPU Ã¨ disponibile, altrimenti gli\n",
        "assegniamo False\"\"\"\n",
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0aDjN4z4BtO"
      },
      "source": [
        "\"\"\"Tale funzione come parametro riceve un modulo presente all'interno del\n",
        "generatore o del discriminatore e se il modulo Ã¨ di tipo Conv o sottotipo di\n",
        "Conv (ad esempio Conv2d) allora vengono inizializzati i pesi di tale modulo, se\n",
        "il modulo Ã¨ di tipo BatchNorm2d allora vengono inizializzati i pesi e i bias di\n",
        "tale modulo\"\"\"\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK9kHnTK6-R3"
      },
      "source": [
        "\"\"\"Modello del generatore\"\"\"\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        \"\"\"Come primo parametro dell'Embedding dobbiamo specificare il numero potenziale\n",
        "        di target differenti che l'Embedding puÃ² ricevere in ingresso.\n",
        "        Come secondo parametro Ã¨ necessario specificare il numero di componenti che ogni\n",
        "        singola rappresentazione generata dall'Embedding dovrÃ  avere.\n",
        "        In questo caso come primo parametro stiamo specificando opt.n_classes in quanto\n",
        "        potenzialmente, il numero di target differenti che possono essere forniti in\n",
        "        ingresso all'Embedding Ã¨ pari al numero di classi a cui puÃ² potenzialmente puÃ²\n",
        "        appartenere ogni singola immagine del dataset.\n",
        "        Come secondo parametro stiamo specificando opt.latent_dim in quanto vogliamo\n",
        "        che ogni singola rappresentazione del target generata dell'Embedding abbia\n",
        "        un numero di componenti pari al numero di componenti del rumore\n",
        "        \"\"\"\n",
        "        self.label_emb = nn.Embedding(opt.n_classes, opt.latent_dim)\n",
        "        self.init_size = opt.img_size // 4  # Initial size before upsampling\n",
        "\n",
        "        \"\"\"Linear in ingresso riceve il Tensor 2-D di dimensione BxN restituito dal\n",
        "        modulo Embedding e in uscita restituisce un Tensor 2-D di dimensione Bx(128x(self.init_size)**2)\n",
        "        \"\"\"\n",
        "        self.l1 = nn.Sequential(\n",
        "            nn.Linear(opt.latent_dim, 128 * self.init_size ** 2)\n",
        "            )\n",
        "        \n",
        "        \"\"\"Come parametro di BatchNorm2d dobbiamo specificare il numero di\n",
        "        canali (feature maps) dell'immagine che viene mandata in ingresso al\n",
        "        modulo\"\"\"\n",
        "\n",
        "        \"\"\"Dal momento che ad Upsample come parametro scale_factor stiamo\n",
        "        specificando 2, di fatto, Upsample riceve in ingresso una determinata\n",
        "        immagine e in uscita produce un'immagine che ha una dimensione doppia\n",
        "        rispetto a quella dell'immagine che ha ricevuto in ingresso\"\"\"\n",
        "\n",
        "        \"\"\"Il primo parametro di Conv2d indica il numero di canali (feature maps)\n",
        "        dell'immagine che viene fornita in ingresso al modulo.\n",
        "        Il secondo parametro di Conv2d indica il numero di canali (feature maps)\n",
        "        dell'immagine che viene prodotta in uscita dal modulo.\n",
        "        \"\"\"\n",
        "        \n",
        "        \"\"\"Il primo parametro di LeakyReLu Ã¨ il cosiddetto negative_slop\n",
        "        mentre il secondo se posto pari a True consente un risparmio della\n",
        "        quantitÃ  di memoria allocata\"\"\"\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, opt.channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        \"\"\"Per prima cosa viene preso il Tensor 1-D labels contenente le B classi a cui\n",
        "        dovranno appartenere le B immagini generate dal generatore e viene passato ad un\n",
        "        modulo Embedding. Il modulo Embedding, dunque, in ingresso riceve un Tensor 1-D\n",
        "        contenente B elementi e in uscita restituisce un Tensor 2-D di dimensione BxN,\n",
        "        ossia un Tensor avente B righe (tante quanti sono i target) e N colonne (tante \n",
        "        quante sono le componenti del rumore). In altre parole, l'Embedding per ogni\n",
        "        singolo target che riceve in ingresso restituisce una rappresentazione compatta\n",
        "        dello stesso.\n",
        "        DopodichÃ©, al reference gen_input viene assegnato un Tensor 2-D risultante dal\n",
        "        prodotto tra ogni singolo elemento del Tensor 2-D restituito dall'Embedding e il\n",
        "        relativo elemento del Tensor 2-D noise\n",
        "        \"\"\"\n",
        "        gen_input = torch.mul(self.label_emb(labels), noise)\n",
        "        out = self.l1(gen_input)\n",
        "        \"\"\"out Ã¨ un Tensor 2-D di dimensione Bx(128x(self.init_size)**2)\"\"\"\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        \"\"\"out Ã¨ un Tensor 4-D di dimensione Bx128x8x8. In pratica, tale Tensor\n",
        "        contiene un numero di immagini pari a B, dove ogni singola immagine ha\n",
        "        128 canali e ha una risoluzione di 8x8\"\"\"\n",
        "        img = self.conv_blocks(out)\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6H5TXqJP9Xd"
      },
      "source": [
        "\"\"\"Modello del discriminatore\"\"\"\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "        \"\"\"L'* che precede discriminator_block Ã¨ dovuto al meccanismo di Unpacking\"\"\"    \n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = opt.img_size // 2 ** 4\n",
        "\n",
        "        # Output layers\n",
        "        \"\"\"Attraverso adv_layer otteniamo la probabilitÃ  che l'immagine\n",
        "        fornita in ingresso al discriminatore sia reale\"\"\"\n",
        "        self.adv_layer = nn.Sequential(\n",
        "            nn.Linear(128 * ds_size ** 2, 1),\n",
        "            nn.Sigmoid()\n",
        "            )\n",
        "        \"\"\"Attraverso aux_layer otteniamo le probabilitÃ  con cui l'immagine che\n",
        "        Ã¨ stata fornita in ingresso al discriminatore appartiene alle diverse\n",
        "        classi a cui potenzialmente puÃ² appartenere\"\"\"\n",
        "        self.aux_layer = nn.Sequential(\n",
        "            nn.Linear(128 * ds_size ** 2, opt.n_classes),\n",
        "            nn.Softmax()\n",
        "            )\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.conv_blocks(img)\n",
        "        \"\"\"out.shape[0] Ã¨ pari a B, ossia al numero di elementi del minibatch\"\"\"\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "        label = self.aux_layer(out)\n",
        "\n",
        "\n",
        "        \"\"\"validity contiene la probabilitÃ  che l'immagine fornita in ingresso\n",
        "        al discriminatore sia reale\n",
        "        label contiene le probabilitÃ  con cui l'immagine che Ã¨ stata fornita\n",
        "        in ingresso al discriminatore appartiene alle diverse classi a cui\n",
        "        potenzialmente puÃ² appartenere\"\"\"\n",
        "        return validity, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhqqllyTW8xc"
      },
      "source": [
        "#Definiamo le Loss Function che ci serviranno\"\"\"\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "auxiliary_loss = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNHLRUb1XcOL"
      },
      "source": [
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXYN7XQGXeE7"
      },
      "source": [
        "\"\"\"Se la GPU Ã¨ disponibile spostiamo i modelli e le Loss all'interno della GPU\"\"\"\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "    auxiliary_loss.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiL4hM7LXqF0",
        "outputId": "cc360745-ebc9-40e0-f17f-e4389f963703"
      },
      "source": [
        "#Inizializziamo i parametri dei moduli presenti all'interno del generatore e del discriminatore\n",
        "\"\"\"Supponiamo di considerare la funzione apply invocata su generator. Tale funzione\n",
        "in maniera iterativa prende ogni singolo modulo presente all'interno di generator\n",
        "e lo passa come parametro della funzione weights_init_normal\"\"\"\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (conv_blocks): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Dropout2d(p=0.25, inplace=False)\n",
              "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Dropout2d(p=0.25, inplace=False)\n",
              "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (9): Dropout2d(p=0.25, inplace=False)\n",
              "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (13): Dropout2d(p=0.25, inplace=False)\n",
              "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (adv_layer): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              "  (aux_layer): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
              "    (1): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa2IObdQYLVL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "6a9ef659cc5f46519e203509fe91990f",
            "da7b036040b54ec387a54cf9d024498a",
            "5a5b4ff6e8444dceb61e88f5e6c2db71",
            "456994c63d594cd19922029715d65bb0",
            "b887f592db524055a7bb4a066602fd6e",
            "03b877a23b4b4b5a9768c712fb9e1b8d",
            "1b4ee9a4e582441ba031fb2650bc6fc1",
            "47f53791513a455ca72cd7c454329988",
            "830abced7fd84ff88300bdc9ef47486a",
            "67c466fd0ac1455babde1389c24d7988",
            "4a5e1721e2f44e1dadf917bfdc6e972b",
            "9eaf918b17f847e99ba19fdf86ddd4e0",
            "977035f38554459ba01abd3dbe1f086e",
            "8edf01ce67d74664b6d917c75d064806",
            "8f56e8ff3ebe4ecab88fab083a2500be",
            "2c2a834f7a4f4070921b383381cd9a9c",
            "ed8390729a094d97b91724d0a56aac9c",
            "65b732ce0f074c1fbaa21207ba6fcae0",
            "31059661c0744addbee994262084b1b7",
            "a727a3e88f9f4fbb95c48d714e9c5bf4",
            "6b12a4dfb5e6449587a83ee6923b5ea7",
            "ad03af148bdf46718d9bfde1ab1befbc",
            "0af765dad10848f59fb5eb8d12b0d153",
            "27c5c30395854a9bbe731267c9c76856",
            "bb68a61ba71a4b4780e60f7ab522815e",
            "18337ec894ba4572a9b5d2db9e13aea5",
            "6305b647030e47c58434bc0b1c8e10dd",
            "c6ecbf7d81214a8280c721b860374662",
            "25295284634f476bbc1dc02921f195c8",
            "3a51dd915ded4f7cb22901986e79bec6",
            "7604dd524e7e4901bf0217431eaa9db9",
            "e895cec77b00423db0b4330ddc93b199"
          ]
        },
        "outputId": "8fa59b5f-ab4d-4149-e4ce-ae9afd95f552"
      },
      "source": [
        "# Configure data loader\n",
        "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"../../data/mnist\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a9ef659cc5f46519e203509fe91990f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "830abced7fd84ff88300bdc9ef47486a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed8390729a094d97b91724d0a56aac9c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb68a61ba71a4b4780e60f7ab522815e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWOVuAJsYhrz"
      },
      "source": [
        "#Creiamo gli ottimizzatori\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW_Xf7BfYr09"
      },
      "source": [
        "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iALlIdR3Y6mM"
      },
      "source": [
        "def sample_image(n_row, epoch):\n",
        "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
        "    # Sample noise\n",
        "    \"\"\"Per generare z, ossia il minibatch contenente rumore casuale da mandare in ingresso\n",
        "    al generatore abbiamo creato un Tensor 2-D avente un numero di righe pari a\n",
        "    n_row**2 e un numero di colonne pari a 100. DopodichÃ©, dal momento che vogliamo\n",
        "    che questo Tensor contenga sempre gli stessi valori anche se la funzione sample_image\n",
        "    viene chiamata piÃ¹ volte abbiamo deciso di wrappare tale Tensor all'interno di Variable.\n",
        "    CosÃ¬ facendo, anche se la funzione sample_image viene chiamata piÃ¹ volte, il valore di z\n",
        "    rimane invariato\"\"\"\n",
        "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))\n",
        "    # Get labels ranging from 0 to n_classes for n rows\n",
        "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
        "    labels = Variable(LongTensor(labels))\n",
        "    \"\"\"Per generare labels, ossia il minibatch contenente i target da mandare in ingresso\n",
        "    al generatore abbiamo creato un Tensor 1-D avente un numero di elementi pari a 100\n",
        "    (numero di righe di z), dove l'elemento di indice 0 assume 0, l'elemento di indice 1 assume 1, l'elemento di indice 2 assume 2\n",
        "    l'elemento di indice 9 assume 9, l'elemento di indice 10 assume 0, l'elemento di indice 11 assume 1 e cosÃ¬ via.\n",
        "    Inoltre, per far si che il valore di labels non cambi nonostante la funzione sample_image venga chiamata piÃ¹ volte abbiamo wrappato\n",
        "    tale Tensor all'interno di Variable\"\"\"\n",
        "    \"\"\"Prendiamo il Tensor 2-D z e il Tensor 1-D labels e mandiamoli in ingresso al generatore\"\"\"\n",
        "    gen_imgs = generator(z, labels)\n",
        "    \"\"\"Il numero di immmagini che vengono prodotte in uscita dal gneratore Ã¨ pari a n_row**2\"\"\"\n",
        "    save_image(gen_imgs.data, \"results_images/Epoca%d.png\" % epoch, nrow=n_row, normalize=True)\n",
        "    \"\"\"Tramite save_image all'interno della directory results_images che abbiamo creato\n",
        "    precedentemente inseriamo una griglia costituita dalle n_row**2 immagini prodotte in uscita\n",
        "    dal generatore disposte su n_row righe\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkbdEPGKnM5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3aab1b-d911-4d8f-ffe7-b9d53f36aa03"
      },
      "source": [
        "for epoch in range(opt.n_epochs):\n",
        "  history_d_minibatch_accuracy = []\n",
        "  history_d_minibatch_loss = []\n",
        "  history_g_minibatch_loss = []\n",
        "  for i, (imgs, labels) in enumerate(dataloader):\n",
        "\n",
        "        batch_size = imgs.shape[0] #64\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
        "        \"\"\"valid Ã¨ un Tensor 2-D avente un numero di righe pari a batch_size(64)\n",
        "        e un numero di colonne pari a 1. Tale Tensor contiene tutti 1 e ci \n",
        "        serve per calcolare l'adversarial loss per le immagini reali\n",
        "        \"\"\"\n",
        "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
        "        \"\"\"fake Ã¨ un Tensor 2-D avente un numero di righe pari a batch_size(64)\n",
        "        e un numero di colonne pari a 1. Tale Tensor contiene tutti 0 e ci \n",
        "        serve per calcolare l'adversarial loss per le immagini fake\n",
        "        \"\"\"\n",
        "\n",
        "        # Configure input\n",
        "        \"\"\"Invocando il metodo type su un Tensor Ã¨ possibile effettuare il\n",
        "        casting di tale Tensor\"\"\"\n",
        "        real_imgs = Variable(imgs.type(FloatTensor))\n",
        "        \"\"\"real_imgs Ã¨ un minibatch contenente un numero di immagini reali pari\n",
        "        a minibatch_size(64)\"\"\"\n",
        "        labels = Variable(labels.type(LongTensor))\n",
        "        \"\"\"labels Ã¨ un minibatch contenente i minibatch_size(64) target\n",
        "        corrispondenti alle 64 immagini reali presenti nel minibatch real_imgs\"\"\"\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "        \"\"\"Resettiamo il gradiente\"\"\"\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise and labels as generator input\n",
        "        \"\"\"z Ã¨ un minibatch contenente 64 rumori casuali, ognuno di 100 elementi\"\"\"\n",
        "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
        "        \"\"\"gen_labels Ã¨ un Tensor 1-D contenente 64 (batch_size) target, uno per\n",
        "        ogni singolo rumore casuale presente nel minibatch z\"\"\"\n",
        "        gen_labels = Variable(LongTensor(np.random.randint(0, opt.n_classes, batch_size)))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z, gen_labels)\n",
        "        \"\"\"gen_imgs Ã¨ un minibatch contenente le 64 immagini (batch_size)\n",
        "        generate dal generatore\"\"\"\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        \"\"\"A questo punto prendiamo il minibatch contenente le 64 immagini\n",
        "        generate dal generatore e le mandiamo in ingresso al discriminatore\"\"\"\n",
        "        validity, pred_label = discriminator(gen_imgs)\n",
        "        g_loss = 0.5 * (adversarial_loss(validity, valid) + auxiliary_loss(pred_label, gen_labels))\n",
        "        \"\"\"Calcoliamo il gradiente della g_loss\"\"\"\n",
        "        g_loss.backward()\n",
        "        \"\"\"Ottimizziamo i parametri del generatore\"\"\"\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        \"\"\"Resettiamo il gradiente\"\"\"\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Loss for real images\n",
        "        real_pred, real_aux = discriminator(real_imgs)\n",
        "        d_real_loss = (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels)) / 2\n",
        "\n",
        "        # Loss for fake images\n",
        "        fake_pred, fake_aux = discriminator(gen_imgs.detach())\n",
        "        \"\"\"gen_imgs contiene le 64 (batch_size) immagini generate dal generatore\n",
        "        durante la fase di training del generatore\"\"\"\n",
        "\n",
        "        \"\"\"Utilizzando detach() nel momento in cui attuiamo la backpropagation\n",
        "        per aggiornare i parametri del discriminatore quello che accade Ã¨ che\n",
        "        effettivamente vengono aggiornati solo ed esclusivamente i parametri del\n",
        "        discriminatore e non anche quelli del generatore.\n",
        "        Se non usassimo detach() nel momento in cui attuaiamo la backpropagation\n",
        "        per aggiornare i parametri del discriminatore, oltre ai parametri del\n",
        "        discriminatore, verrebbero aggiornati anche quelli del generatore e questo\n",
        "        non va bene in quanto vogliamo aggiornare solo i parametri del\n",
        "        discriminatore\"\"\"\n",
        "        d_fake_loss = (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, gen_labels)) / 2\n",
        "\n",
        "        # Total discriminator loss\n",
        "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "        \"\"\"Calcoliamo il gradiente della loss del discriminatore\"\"\"\n",
        "        d_loss.backward()\n",
        "        \"\"\"Ottimizziamo i parametri del discriminatore\"\"\"\n",
        "        optimizer_D.step()\n",
        "\n",
        "\n",
        "        #Calcoliamo l'accuratezza del discriminatore nel classificare correttamente la classe di appartenenza di ogni singola immagine (fake o reale) che riceve\n",
        "        pred = np.concatenate([real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0)\n",
        "        \"\"\"pred ha dimensione 128x10 in quanto Ã¨ dato dalla concatenazione per riga\n",
        "        di real_aux (Tensor 2-D di dimensione 64x10 contenente per ogni immagine reale fornita al discriminatore\n",
        "        le probabilitÃ  con cui l'immagine appartiene ad ognuna delle 10 classi) e di\n",
        "        fake_aux (Tensor 2-D di dimensione 64x10 contenente per ogni immagine fake fornita al discriminatore\n",
        "        le probabilitÃ  con cui l'immagine appartiene ad ognuna delle 10 classi)\"\"\"\n",
        "        target = np.concatenate([labels.data.cpu().numpy(), gen_labels.data.cpu().numpy()], axis=0)\n",
        "        \"\"\"target ha dimensione 128 in quanto Ã¨ dato dalla concatenazione per riga\n",
        "        di labels (Tensor 1-D di dimensione 64 contenente per ogni immagine reale fornita al discriminatore il relativo target)\n",
        "        e di gen_labels (Tensor 1-D di dimensione 64 contenente per ogni immagine fake fornita al discriminatore il relativo target)\n",
        "        \"\"\"\n",
        "        d_minibatch_accuracy = np.mean(np.argmax(pred, axis=1) == target)\n",
        "        history_d_minibatch_accuracy.append(d_minibatch_accuracy)\n",
        "        history_d_minibatch_loss.append(d_loss.item())\n",
        "        history_g_minibatch_loss.append(g_loss.item())\n",
        "\n",
        "        if (epoch+1) % opt.sample_interval == 0:\n",
        "            sample_image(n_row=10, epoch=epoch+1)\n",
        "\n",
        "  d_epoch_accuracy = np.mean(history_d_minibatch_accuracy)\n",
        "  d_epoch_loss = np.mean(history_d_minibatch_loss)\n",
        "  g_epoch_loss = np.mean(history_g_minibatch_loss)\n",
        "  print(f\"Epoch {epoch+1}: Discriminator_Loss={d_epoch_loss:.4f}, Discriminator_Accuracy={d_epoch_accuracy*100:.4f}, Generator_Loss={g_epoch_loss:.4f}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: Discriminator_Loss=1.3400, Discriminator_Accuracy=45.3183, Generator_Loss=1.4187\n",
            "Epoch 2: Discriminator_Loss=1.1012, Discriminator_Accuracy=88.5178, Generator_Loss=1.2245\n",
            "Epoch 3: Discriminator_Loss=1.0850, Discriminator_Accuracy=92.8163, Generator_Loss=1.1882\n",
            "Epoch 4: Discriminator_Loss=1.0842, Discriminator_Accuracy=94.0898, Generator_Loss=1.1694\n",
            "Epoch 5: Discriminator_Loss=1.0874, Discriminator_Accuracy=94.8144, Generator_Loss=1.1435\n",
            "Epoch 6: Discriminator_Loss=1.0905, Discriminator_Accuracy=95.3858, Generator_Loss=1.1279\n",
            "Epoch 7: Discriminator_Loss=1.0924, Discriminator_Accuracy=95.9355, Generator_Loss=1.1159\n",
            "Epoch 8: Discriminator_Loss=1.0926, Discriminator_Accuracy=96.1354, Generator_Loss=1.1079\n",
            "Epoch 9: Discriminator_Loss=1.0928, Discriminator_Accuracy=96.4844, Generator_Loss=1.1036\n",
            "Epoch 10: Discriminator_Loss=1.0913, Discriminator_Accuracy=96.6010, Generator_Loss=1.1017\n",
            "Epoch 11: Discriminator_Loss=1.0927, Discriminator_Accuracy=96.8467, Generator_Loss=1.0986\n",
            "Epoch 12: Discriminator_Loss=1.0897, Discriminator_Accuracy=97.1099, Generator_Loss=1.0965\n",
            "Epoch 13: Discriminator_Loss=1.0889, Discriminator_Accuracy=97.2290, Generator_Loss=1.0952\n",
            "Epoch 14: Discriminator_Loss=1.0873, Discriminator_Accuracy=97.3797, Generator_Loss=1.0940\n",
            "Epoch 15: Discriminator_Loss=1.0870, Discriminator_Accuracy=97.4222, Generator_Loss=1.0960\n",
            "Epoch 16: Discriminator_Loss=1.0867, Discriminator_Accuracy=97.5413, Generator_Loss=1.0963\n",
            "Epoch 17: Discriminator_Loss=1.0864, Discriminator_Accuracy=97.6054, Generator_Loss=1.0939\n",
            "Epoch 18: Discriminator_Loss=1.0852, Discriminator_Accuracy=97.6179, Generator_Loss=1.0951\n",
            "Epoch 19: Discriminator_Loss=1.0850, Discriminator_Accuracy=97.7079, Generator_Loss=1.0969\n",
            "Epoch 20: Discriminator_Loss=1.0834, Discriminator_Accuracy=97.7604, Generator_Loss=1.0980\n",
            "Epoch 21: Discriminator_Loss=1.0818, Discriminator_Accuracy=97.7495, Generator_Loss=1.1020\n",
            "Epoch 22: Discriminator_Loss=1.0780, Discriminator_Accuracy=97.7770, Generator_Loss=1.1025\n",
            "Epoch 23: Discriminator_Loss=1.0751, Discriminator_Accuracy=97.7837, Generator_Loss=1.1130\n",
            "Epoch 24: Discriminator_Loss=1.0714, Discriminator_Accuracy=97.7620, Generator_Loss=1.1220\n",
            "Epoch 25: Discriminator_Loss=1.0710, Discriminator_Accuracy=97.7545, Generator_Loss=1.1165\n",
            "Epoch 26: Discriminator_Loss=1.0713, Discriminator_Accuracy=97.7795, Generator_Loss=1.1246\n",
            "Epoch 27: Discriminator_Loss=1.0711, Discriminator_Accuracy=97.7429, Generator_Loss=1.1255\n",
            "Epoch 28: Discriminator_Loss=1.0689, Discriminator_Accuracy=97.7104, Generator_Loss=1.1241\n",
            "Epoch 29: Discriminator_Loss=1.0646, Discriminator_Accuracy=97.6962, Generator_Loss=1.1338\n",
            "Epoch 30: Discriminator_Loss=1.0652, Discriminator_Accuracy=97.7146, Generator_Loss=1.1327\n",
            "Epoch 31: Discriminator_Loss=1.0631, Discriminator_Accuracy=97.7312, Generator_Loss=1.1416\n",
            "Epoch 32: Discriminator_Loss=1.0687, Discriminator_Accuracy=97.6679, Generator_Loss=1.1358\n",
            "Epoch 33: Discriminator_Loss=1.0669, Discriminator_Accuracy=97.6504, Generator_Loss=1.1376\n",
            "Epoch 34: Discriminator_Loss=1.0650, Discriminator_Accuracy=97.6246, Generator_Loss=1.1454\n",
            "Epoch 35: Discriminator_Loss=1.0671, Discriminator_Accuracy=97.5780, Generator_Loss=1.1413\n",
            "Epoch 36: Discriminator_Loss=1.0659, Discriminator_Accuracy=97.7004, Generator_Loss=1.1411\n",
            "Epoch 37: Discriminator_Loss=1.0668, Discriminator_Accuracy=97.7304, Generator_Loss=1.1430\n",
            "Epoch 38: Discriminator_Loss=1.0669, Discriminator_Accuracy=97.6787, Generator_Loss=1.1432\n",
            "Epoch 39: Discriminator_Loss=1.0656, Discriminator_Accuracy=97.6438, Generator_Loss=1.1388\n",
            "Epoch 40: Discriminator_Loss=1.0624, Discriminator_Accuracy=97.6779, Generator_Loss=1.1414\n",
            "Epoch 41: Discriminator_Loss=1.0649, Discriminator_Accuracy=97.5938, Generator_Loss=1.1443\n",
            "Epoch 42: Discriminator_Loss=1.0700, Discriminator_Accuracy=97.6354, Generator_Loss=1.1402\n",
            "Epoch 43: Discriminator_Loss=1.0661, Discriminator_Accuracy=97.5888, Generator_Loss=1.1443\n",
            "Epoch 44: Discriminator_Loss=1.0582, Discriminator_Accuracy=97.6379, Generator_Loss=1.1420\n",
            "Epoch 45: Discriminator_Loss=1.0633, Discriminator_Accuracy=97.6046, Generator_Loss=1.1452\n",
            "Epoch 46: Discriminator_Loss=1.0631, Discriminator_Accuracy=97.5979, Generator_Loss=1.1468\n",
            "Epoch 47: Discriminator_Loss=1.0651, Discriminator_Accuracy=97.5979, Generator_Loss=1.1433\n",
            "Epoch 48: Discriminator_Loss=1.0650, Discriminator_Accuracy=97.6354, Generator_Loss=1.1472\n",
            "Epoch 49: Discriminator_Loss=1.0679, Discriminator_Accuracy=97.6263, Generator_Loss=1.1498\n",
            "Epoch 50: Discriminator_Loss=1.0651, Discriminator_Accuracy=97.6454, Generator_Loss=1.1466\n",
            "Epoch 51: Discriminator_Loss=1.0625, Discriminator_Accuracy=97.6171, Generator_Loss=1.1517\n",
            "Epoch 52: Discriminator_Loss=1.0628, Discriminator_Accuracy=97.5555, Generator_Loss=1.1503\n",
            "Epoch 53: Discriminator_Loss=1.0601, Discriminator_Accuracy=97.6604, Generator_Loss=1.1474\n",
            "Epoch 54: Discriminator_Loss=1.0625, Discriminator_Accuracy=97.6346, Generator_Loss=1.1502\n",
            "Epoch 55: Discriminator_Loss=1.0606, Discriminator_Accuracy=97.6238, Generator_Loss=1.1503\n",
            "Epoch 56: Discriminator_Loss=1.0601, Discriminator_Accuracy=97.6054, Generator_Loss=1.1525\n",
            "Epoch 57: Discriminator_Loss=1.0634, Discriminator_Accuracy=97.5755, Generator_Loss=1.1636\n",
            "Epoch 58: Discriminator_Loss=1.0632, Discriminator_Accuracy=97.5855, Generator_Loss=1.1533\n",
            "Epoch 59: Discriminator_Loss=1.0645, Discriminator_Accuracy=97.5871, Generator_Loss=1.1451\n",
            "Epoch 60: Discriminator_Loss=1.0628, Discriminator_Accuracy=97.5780, Generator_Loss=1.1528\n",
            "Epoch 61: Discriminator_Loss=1.0634, Discriminator_Accuracy=97.5430, Generator_Loss=1.1529\n",
            "Epoch 62: Discriminator_Loss=1.0640, Discriminator_Accuracy=97.5438, Generator_Loss=1.1559\n",
            "Epoch 63: Discriminator_Loss=1.0666, Discriminator_Accuracy=97.5796, Generator_Loss=1.1523\n",
            "Epoch 64: Discriminator_Loss=1.0638, Discriminator_Accuracy=97.5730, Generator_Loss=1.1558\n",
            "Epoch 65: Discriminator_Loss=1.0638, Discriminator_Accuracy=97.5755, Generator_Loss=1.1500\n",
            "Epoch 66: Discriminator_Loss=1.0639, Discriminator_Accuracy=97.6271, Generator_Loss=1.1493\n",
            "Epoch 67: Discriminator_Loss=1.0652, Discriminator_Accuracy=97.4963, Generator_Loss=1.1507\n",
            "Epoch 68: Discriminator_Loss=1.0625, Discriminator_Accuracy=97.4997, Generator_Loss=1.1598\n",
            "Epoch 69: Discriminator_Loss=1.0633, Discriminator_Accuracy=97.5396, Generator_Loss=1.1514\n",
            "Epoch 70: Discriminator_Loss=1.0640, Discriminator_Accuracy=97.4788, Generator_Loss=1.1580\n",
            "Epoch 71: Discriminator_Loss=1.0676, Discriminator_Accuracy=97.4888, Generator_Loss=1.1569\n",
            "Epoch 72: Discriminator_Loss=1.0615, Discriminator_Accuracy=97.4280, Generator_Loss=1.1548\n",
            "Epoch 73: Discriminator_Loss=1.0608, Discriminator_Accuracy=97.4997, Generator_Loss=1.1483\n",
            "Epoch 74: Discriminator_Loss=1.0593, Discriminator_Accuracy=97.5471, Generator_Loss=1.1597\n",
            "Epoch 75: Discriminator_Loss=1.0637, Discriminator_Accuracy=97.5346, Generator_Loss=1.1510\n",
            "Epoch 76: Discriminator_Loss=1.0638, Discriminator_Accuracy=97.4422, Generator_Loss=1.1547\n",
            "Epoch 77: Discriminator_Loss=1.0639, Discriminator_Accuracy=97.5455, Generator_Loss=1.1552\n",
            "Epoch 78: Discriminator_Loss=1.0651, Discriminator_Accuracy=97.4747, Generator_Loss=1.1589\n",
            "Epoch 79: Discriminator_Loss=1.0640, Discriminator_Accuracy=97.4530, Generator_Loss=1.1551\n",
            "Epoch 80: Discriminator_Loss=1.0635, Discriminator_Accuracy=97.5280, Generator_Loss=1.1480\n",
            "Epoch 81: Discriminator_Loss=1.0601, Discriminator_Accuracy=97.5330, Generator_Loss=1.1619\n",
            "Epoch 82: Discriminator_Loss=1.0600, Discriminator_Accuracy=97.4564, Generator_Loss=1.1617\n",
            "Epoch 83: Discriminator_Loss=1.0655, Discriminator_Accuracy=97.5188, Generator_Loss=1.1563\n",
            "Epoch 84: Discriminator_Loss=1.0604, Discriminator_Accuracy=97.4797, Generator_Loss=1.1559\n",
            "Epoch 85: Discriminator_Loss=1.0620, Discriminator_Accuracy=97.4255, Generator_Loss=1.1581\n",
            "Epoch 86: Discriminator_Loss=1.0599, Discriminator_Accuracy=97.5238, Generator_Loss=1.1604\n",
            "Epoch 87: Discriminator_Loss=1.0610, Discriminator_Accuracy=97.4988, Generator_Loss=1.1572\n",
            "Epoch 88: Discriminator_Loss=1.0582, Discriminator_Accuracy=97.4614, Generator_Loss=1.1668\n",
            "Epoch 89: Discriminator_Loss=1.0581, Discriminator_Accuracy=97.5222, Generator_Loss=1.1634\n",
            "Epoch 90: Discriminator_Loss=1.0597, Discriminator_Accuracy=97.4680, Generator_Loss=1.1695\n",
            "Epoch 91: Discriminator_Loss=1.0568, Discriminator_Accuracy=97.5147, Generator_Loss=1.1733\n",
            "Epoch 92: Discriminator_Loss=1.0600, Discriminator_Accuracy=97.5280, Generator_Loss=1.1656\n",
            "Epoch 93: Discriminator_Loss=1.0599, Discriminator_Accuracy=97.5205, Generator_Loss=1.1749\n",
            "Epoch 94: Discriminator_Loss=1.0569, Discriminator_Accuracy=97.5471, Generator_Loss=1.1683\n",
            "Epoch 95: Discriminator_Loss=1.0599, Discriminator_Accuracy=97.4872, Generator_Loss=1.1711\n",
            "Epoch 96: Discriminator_Loss=1.0546, Discriminator_Accuracy=97.5346, Generator_Loss=1.1704\n",
            "Epoch 97: Discriminator_Loss=1.0544, Discriminator_Accuracy=97.4713, Generator_Loss=1.1623\n",
            "Epoch 98: Discriminator_Loss=1.0548, Discriminator_Accuracy=97.4788, Generator_Loss=1.1849\n",
            "Epoch 99: Discriminator_Loss=1.0578, Discriminator_Accuracy=97.4847, Generator_Loss=1.1618\n",
            "Epoch 100: Discriminator_Loss=1.0573, Discriminator_Accuracy=97.3522, Generator_Loss=1.1722\n",
            "Epoch 101: Discriminator_Loss=1.0577, Discriminator_Accuracy=97.4272, Generator_Loss=1.1664\n",
            "Epoch 102: Discriminator_Loss=1.0609, Discriminator_Accuracy=97.4355, Generator_Loss=1.1762\n",
            "Epoch 103: Discriminator_Loss=1.0553, Discriminator_Accuracy=97.3781, Generator_Loss=1.1754\n",
            "Epoch 104: Discriminator_Loss=1.0556, Discriminator_Accuracy=97.4255, Generator_Loss=1.1783\n",
            "Epoch 105: Discriminator_Loss=1.0530, Discriminator_Accuracy=97.4122, Generator_Loss=1.1754\n",
            "Epoch 106: Discriminator_Loss=1.0580, Discriminator_Accuracy=97.4297, Generator_Loss=1.1726\n",
            "Epoch 107: Discriminator_Loss=1.0565, Discriminator_Accuracy=97.4397, Generator_Loss=1.1781\n",
            "Epoch 108: Discriminator_Loss=1.0592, Discriminator_Accuracy=97.3889, Generator_Loss=1.1785\n",
            "Epoch 109: Discriminator_Loss=1.0560, Discriminator_Accuracy=97.3706, Generator_Loss=1.1839\n",
            "Epoch 110: Discriminator_Loss=1.0556, Discriminator_Accuracy=97.4847, Generator_Loss=1.1765\n",
            "Epoch 111: Discriminator_Loss=1.0548, Discriminator_Accuracy=97.4805, Generator_Loss=1.1860\n",
            "Epoch 112: Discriminator_Loss=1.0610, Discriminator_Accuracy=97.3889, Generator_Loss=1.1777\n",
            "Epoch 113: Discriminator_Loss=1.0612, Discriminator_Accuracy=97.4305, Generator_Loss=1.1733\n",
            "Epoch 114: Discriminator_Loss=1.0559, Discriminator_Accuracy=97.4031, Generator_Loss=1.1776\n",
            "Epoch 115: Discriminator_Loss=1.0530, Discriminator_Accuracy=97.4339, Generator_Loss=1.1836\n",
            "Epoch 116: Discriminator_Loss=1.0506, Discriminator_Accuracy=97.4472, Generator_Loss=1.1802\n",
            "Epoch 117: Discriminator_Loss=1.0518, Discriminator_Accuracy=97.4855, Generator_Loss=1.1808\n",
            "Epoch 118: Discriminator_Loss=1.0561, Discriminator_Accuracy=97.4197, Generator_Loss=1.1806\n",
            "Epoch 119: Discriminator_Loss=1.0493, Discriminator_Accuracy=97.4355, Generator_Loss=1.1772\n",
            "Epoch 120: Discriminator_Loss=1.0538, Discriminator_Accuracy=97.3806, Generator_Loss=1.1679\n",
            "Epoch 121: Discriminator_Loss=1.0557, Discriminator_Accuracy=97.4322, Generator_Loss=1.1808\n",
            "Epoch 122: Discriminator_Loss=1.0519, Discriminator_Accuracy=97.3939, Generator_Loss=1.1815\n",
            "Epoch 123: Discriminator_Loss=1.0505, Discriminator_Accuracy=97.3614, Generator_Loss=1.1887\n",
            "Epoch 124: Discriminator_Loss=1.0508, Discriminator_Accuracy=97.4056, Generator_Loss=1.1919\n",
            "Epoch 125: Discriminator_Loss=1.0524, Discriminator_Accuracy=97.3972, Generator_Loss=1.1919\n",
            "Epoch 126: Discriminator_Loss=1.0539, Discriminator_Accuracy=97.3872, Generator_Loss=1.1901\n",
            "Epoch 127: Discriminator_Loss=1.0504, Discriminator_Accuracy=97.4539, Generator_Loss=1.1906\n",
            "Epoch 128: Discriminator_Loss=1.0603, Discriminator_Accuracy=97.2481, Generator_Loss=1.1916\n",
            "Epoch 129: Discriminator_Loss=1.0480, Discriminator_Accuracy=97.4530, Generator_Loss=1.1866\n",
            "Epoch 130: Discriminator_Loss=1.0508, Discriminator_Accuracy=97.3997, Generator_Loss=1.1877\n",
            "Epoch 131: Discriminator_Loss=1.0533, Discriminator_Accuracy=97.4114, Generator_Loss=1.1799\n",
            "Epoch 132: Discriminator_Loss=1.0583, Discriminator_Accuracy=97.3189, Generator_Loss=1.1899\n",
            "Epoch 133: Discriminator_Loss=1.0472, Discriminator_Accuracy=97.4031, Generator_Loss=1.2054\n",
            "Epoch 134: Discriminator_Loss=1.0552, Discriminator_Accuracy=97.2631, Generator_Loss=1.1945\n",
            "Epoch 135: Discriminator_Loss=1.0546, Discriminator_Accuracy=97.3181, Generator_Loss=1.1937\n",
            "Epoch 136: Discriminator_Loss=1.0529, Discriminator_Accuracy=97.3289, Generator_Loss=1.1813\n",
            "Epoch 137: Discriminator_Loss=1.0522, Discriminator_Accuracy=97.3281, Generator_Loss=1.1828\n",
            "Epoch 138: Discriminator_Loss=1.0542, Discriminator_Accuracy=97.3764, Generator_Loss=1.1900\n",
            "Epoch 139: Discriminator_Loss=1.0494, Discriminator_Accuracy=97.2981, Generator_Loss=1.1851\n",
            "Epoch 140: Discriminator_Loss=1.0457, Discriminator_Accuracy=97.3506, Generator_Loss=1.1924\n",
            "Epoch 141: Discriminator_Loss=1.0476, Discriminator_Accuracy=97.3356, Generator_Loss=1.2030\n",
            "Epoch 142: Discriminator_Loss=1.0535, Discriminator_Accuracy=97.3414, Generator_Loss=1.2027\n",
            "Epoch 143: Discriminator_Loss=1.0483, Discriminator_Accuracy=97.3389, Generator_Loss=1.2033\n",
            "Epoch 144: Discriminator_Loss=1.0467, Discriminator_Accuracy=97.3006, Generator_Loss=1.2036\n",
            "Epoch 145: Discriminator_Loss=1.0522, Discriminator_Accuracy=97.3339, Generator_Loss=1.2032\n",
            "Epoch 146: Discriminator_Loss=1.0455, Discriminator_Accuracy=97.3406, Generator_Loss=1.2086\n",
            "Epoch 147: Discriminator_Loss=1.0487, Discriminator_Accuracy=97.4122, Generator_Loss=1.1964\n",
            "Epoch 148: Discriminator_Loss=1.0523, Discriminator_Accuracy=97.2615, Generator_Loss=1.2082\n",
            "Epoch 149: Discriminator_Loss=1.0446, Discriminator_Accuracy=97.2723, Generator_Loss=1.2094\n",
            "Epoch 150: Discriminator_Loss=1.0482, Discriminator_Accuracy=97.1049, Generator_Loss=1.2118\n",
            "Epoch 151: Discriminator_Loss=1.0492, Discriminator_Accuracy=97.2565, Generator_Loss=1.2003\n",
            "Epoch 152: Discriminator_Loss=1.0481, Discriminator_Accuracy=97.2631, Generator_Loss=1.1945\n",
            "Epoch 153: Discriminator_Loss=1.0516, Discriminator_Accuracy=97.2631, Generator_Loss=1.1985\n",
            "Epoch 154: Discriminator_Loss=1.0494, Discriminator_Accuracy=97.2790, Generator_Loss=1.2130\n",
            "Epoch 155: Discriminator_Loss=1.0524, Discriminator_Accuracy=97.2523, Generator_Loss=1.2017\n",
            "Epoch 156: Discriminator_Loss=1.0486, Discriminator_Accuracy=97.2565, Generator_Loss=1.2014\n",
            "Epoch 157: Discriminator_Loss=1.0457, Discriminator_Accuracy=97.2290, Generator_Loss=1.2189\n",
            "Epoch 158: Discriminator_Loss=1.0459, Discriminator_Accuracy=97.2223, Generator_Loss=1.2112\n",
            "Epoch 159: Discriminator_Loss=1.0471, Discriminator_Accuracy=97.2923, Generator_Loss=1.2107\n",
            "Epoch 160: Discriminator_Loss=1.0454, Discriminator_Accuracy=97.2206, Generator_Loss=1.2042\n",
            "Epoch 161: Discriminator_Loss=1.0492, Discriminator_Accuracy=97.2465, Generator_Loss=1.2188\n",
            "Epoch 162: Discriminator_Loss=1.0440, Discriminator_Accuracy=97.1740, Generator_Loss=1.2150\n",
            "Epoch 163: Discriminator_Loss=1.0453, Discriminator_Accuracy=97.0891, Generator_Loss=1.2136\n",
            "Epoch 164: Discriminator_Loss=1.0489, Discriminator_Accuracy=97.2265, Generator_Loss=1.2204\n",
            "Epoch 165: Discriminator_Loss=1.0464, Discriminator_Accuracy=97.1890, Generator_Loss=1.2209\n",
            "Epoch 166: Discriminator_Loss=1.0456, Discriminator_Accuracy=97.2157, Generator_Loss=1.2308\n",
            "Epoch 167: Discriminator_Loss=1.0438, Discriminator_Accuracy=97.2007, Generator_Loss=1.2240\n",
            "Epoch 168: Discriminator_Loss=1.0402, Discriminator_Accuracy=97.2540, Generator_Loss=1.2165\n",
            "Epoch 169: Discriminator_Loss=1.0400, Discriminator_Accuracy=97.2748, Generator_Loss=1.2212\n",
            "Epoch 170: Discriminator_Loss=1.0466, Discriminator_Accuracy=97.2315, Generator_Loss=1.2107\n",
            "Epoch 171: Discriminator_Loss=1.0483, Discriminator_Accuracy=97.2023, Generator_Loss=1.2182\n",
            "Epoch 172: Discriminator_Loss=1.0384, Discriminator_Accuracy=97.2298, Generator_Loss=1.2275\n",
            "Epoch 173: Discriminator_Loss=1.0410, Discriminator_Accuracy=97.1798, Generator_Loss=1.2269\n",
            "Epoch 174: Discriminator_Loss=1.0446, Discriminator_Accuracy=97.2806, Generator_Loss=1.2191\n",
            "Epoch 175: Discriminator_Loss=1.0431, Discriminator_Accuracy=97.2964, Generator_Loss=1.2228\n",
            "Epoch 176: Discriminator_Loss=1.0438, Discriminator_Accuracy=97.1898, Generator_Loss=1.2162\n",
            "Epoch 177: Discriminator_Loss=1.0431, Discriminator_Accuracy=97.2723, Generator_Loss=1.2235\n",
            "Epoch 178: Discriminator_Loss=1.0422, Discriminator_Accuracy=97.2690, Generator_Loss=1.2332\n",
            "Epoch 179: Discriminator_Loss=1.0408, Discriminator_Accuracy=97.2631, Generator_Loss=1.2416\n",
            "Epoch 180: Discriminator_Loss=1.0349, Discriminator_Accuracy=97.2998, Generator_Loss=1.2391\n",
            "Epoch 181: Discriminator_Loss=1.0421, Discriminator_Accuracy=97.2373, Generator_Loss=1.2161\n",
            "Epoch 182: Discriminator_Loss=1.0428, Discriminator_Accuracy=97.2157, Generator_Loss=1.2206\n",
            "Epoch 183: Discriminator_Loss=1.0392, Discriminator_Accuracy=97.1390, Generator_Loss=1.2337\n",
            "Epoch 184: Discriminator_Loss=1.0402, Discriminator_Accuracy=97.2440, Generator_Loss=1.2281\n",
            "Epoch 185: Discriminator_Loss=1.0420, Discriminator_Accuracy=97.1723, Generator_Loss=1.2426\n",
            "Epoch 186: Discriminator_Loss=1.0348, Discriminator_Accuracy=97.1099, Generator_Loss=1.2327\n",
            "Epoch 187: Discriminator_Loss=1.0390, Discriminator_Accuracy=97.1890, Generator_Loss=1.2312\n",
            "Epoch 188: Discriminator_Loss=1.0394, Discriminator_Accuracy=97.1099, Generator_Loss=1.2332\n",
            "Epoch 189: Discriminator_Loss=1.0449, Discriminator_Accuracy=97.2098, Generator_Loss=1.2245\n",
            "Epoch 190: Discriminator_Loss=1.0382, Discriminator_Accuracy=97.0283, Generator_Loss=1.2335\n",
            "Epoch 191: Discriminator_Loss=1.0432, Discriminator_Accuracy=97.0807, Generator_Loss=1.2460\n",
            "Epoch 192: Discriminator_Loss=1.0358, Discriminator_Accuracy=97.1582, Generator_Loss=1.2327\n",
            "Epoch 193: Discriminator_Loss=1.0458, Discriminator_Accuracy=97.2373, Generator_Loss=1.2380\n",
            "Epoch 194: Discriminator_Loss=1.0338, Discriminator_Accuracy=97.1182, Generator_Loss=1.2378\n",
            "Epoch 195: Discriminator_Loss=1.0404, Discriminator_Accuracy=97.1607, Generator_Loss=1.2442\n",
            "Epoch 196: Discriminator_Loss=1.0415, Discriminator_Accuracy=97.1882, Generator_Loss=1.2348\n",
            "Epoch 197: Discriminator_Loss=1.0347, Discriminator_Accuracy=97.0674, Generator_Loss=1.2269\n",
            "Epoch 198: Discriminator_Loss=1.0341, Discriminator_Accuracy=97.0682, Generator_Loss=1.2554\n",
            "Epoch 199: Discriminator_Loss=1.0356, Discriminator_Accuracy=97.1432, Generator_Loss=1.2457\n",
            "Epoch 200: Discriminator_Loss=1.0309, Discriminator_Accuracy=97.1623, Generator_Loss=1.2379\n",
            "Epoch 201: Discriminator_Loss=1.0395, Discriminator_Accuracy=97.0616, Generator_Loss=1.2490\n",
            "Epoch 202: Discriminator_Loss=1.0370, Discriminator_Accuracy=97.0774, Generator_Loss=1.2505\n",
            "Epoch 203: Discriminator_Loss=1.0468, Discriminator_Accuracy=97.0324, Generator_Loss=1.2507\n",
            "Epoch 204: Discriminator_Loss=1.0338, Discriminator_Accuracy=97.0691, Generator_Loss=1.2464\n",
            "Epoch 205: Discriminator_Loss=1.0444, Discriminator_Accuracy=97.0166, Generator_Loss=1.2555\n",
            "Epoch 206: Discriminator_Loss=1.0363, Discriminator_Accuracy=97.1232, Generator_Loss=1.2432\n",
            "Epoch 207: Discriminator_Loss=1.0348, Discriminator_Accuracy=97.1532, Generator_Loss=1.2555\n",
            "Epoch 208: Discriminator_Loss=1.0321, Discriminator_Accuracy=97.1215, Generator_Loss=1.2639\n",
            "Epoch 209: Discriminator_Loss=1.0391, Discriminator_Accuracy=97.0216, Generator_Loss=1.2644\n",
            "Epoch 210: Discriminator_Loss=1.0356, Discriminator_Accuracy=97.1315, Generator_Loss=1.2738\n",
            "Epoch 211: Discriminator_Loss=1.0389, Discriminator_Accuracy=97.0974, Generator_Loss=1.2542\n",
            "Epoch 212: Discriminator_Loss=1.0387, Discriminator_Accuracy=97.0965, Generator_Loss=1.2465\n",
            "Epoch 213: Discriminator_Loss=1.0308, Discriminator_Accuracy=97.0349, Generator_Loss=1.2487\n",
            "Epoch 214: Discriminator_Loss=1.0281, Discriminator_Accuracy=97.0657, Generator_Loss=1.2722\n",
            "Epoch 215: Discriminator_Loss=1.0351, Discriminator_Accuracy=97.0024, Generator_Loss=1.2698\n",
            "Epoch 216: Discriminator_Loss=1.0307, Discriminator_Accuracy=97.1074, Generator_Loss=1.2716\n",
            "Epoch 217: Discriminator_Loss=1.0247, Discriminator_Accuracy=97.1499, Generator_Loss=1.2636\n",
            "Epoch 218: Discriminator_Loss=1.0303, Discriminator_Accuracy=97.0249, Generator_Loss=1.2818\n",
            "Epoch 219: Discriminator_Loss=1.0325, Discriminator_Accuracy=97.0466, Generator_Loss=1.2780\n",
            "Epoch 220: Discriminator_Loss=1.0209, Discriminator_Accuracy=97.0682, Generator_Loss=1.2769\n",
            "Epoch 221: Discriminator_Loss=1.0313, Discriminator_Accuracy=97.1090, Generator_Loss=1.2727\n",
            "Epoch 222: Discriminator_Loss=1.0294, Discriminator_Accuracy=97.0441, Generator_Loss=1.2500\n",
            "Epoch 223: Discriminator_Loss=1.0322, Discriminator_Accuracy=97.0382, Generator_Loss=1.2636\n",
            "Epoch 224: Discriminator_Loss=1.0224, Discriminator_Accuracy=97.0116, Generator_Loss=1.2670\n",
            "Epoch 225: Discriminator_Loss=1.0332, Discriminator_Accuracy=96.9666, Generator_Loss=1.2716\n",
            "Epoch 226: Discriminator_Loss=1.0226, Discriminator_Accuracy=97.0766, Generator_Loss=1.2578\n",
            "Epoch 227: Discriminator_Loss=1.0297, Discriminator_Accuracy=97.0599, Generator_Loss=1.2809\n",
            "Epoch 228: Discriminator_Loss=1.0270, Discriminator_Accuracy=97.0724, Generator_Loss=1.2657\n",
            "Epoch 229: Discriminator_Loss=1.0275, Discriminator_Accuracy=97.0249, Generator_Loss=1.2865\n",
            "Epoch 230: Discriminator_Loss=1.0276, Discriminator_Accuracy=97.0199, Generator_Loss=1.2872\n",
            "Epoch 231: Discriminator_Loss=1.0187, Discriminator_Accuracy=97.0316, Generator_Loss=1.2876\n",
            "Epoch 232: Discriminator_Loss=1.0251, Discriminator_Accuracy=97.0158, Generator_Loss=1.3129\n",
            "Epoch 233: Discriminator_Loss=1.0229, Discriminator_Accuracy=97.0266, Generator_Loss=1.2867\n",
            "Epoch 234: Discriminator_Loss=1.0270, Discriminator_Accuracy=96.9475, Generator_Loss=1.2813\n",
            "Epoch 235: Discriminator_Loss=1.0282, Discriminator_Accuracy=97.0116, Generator_Loss=1.2920\n",
            "Epoch 236: Discriminator_Loss=1.0274, Discriminator_Accuracy=97.0399, Generator_Loss=1.2775\n",
            "Epoch 237: Discriminator_Loss=1.0235, Discriminator_Accuracy=96.9808, Generator_Loss=1.2848\n",
            "Epoch 238: Discriminator_Loss=1.0273, Discriminator_Accuracy=96.9575, Generator_Loss=1.2799\n",
            "Epoch 239: Discriminator_Loss=1.0216, Discriminator_Accuracy=96.9325, Generator_Loss=1.3043\n",
            "Epoch 240: Discriminator_Loss=1.0211, Discriminator_Accuracy=96.9266, Generator_Loss=1.2990\n",
            "Epoch 241: Discriminator_Loss=1.0236, Discriminator_Accuracy=97.0166, Generator_Loss=1.2942\n",
            "Epoch 242: Discriminator_Loss=1.0238, Discriminator_Accuracy=97.0133, Generator_Loss=1.2820\n",
            "Epoch 243: Discriminator_Loss=1.0276, Discriminator_Accuracy=96.9858, Generator_Loss=1.2921\n",
            "Epoch 244: Discriminator_Loss=1.0278, Discriminator_Accuracy=96.8583, Generator_Loss=1.3008\n",
            "Epoch 245: Discriminator_Loss=1.0258, Discriminator_Accuracy=96.9475, Generator_Loss=1.2853\n",
            "Epoch 246: Discriminator_Loss=1.0203, Discriminator_Accuracy=97.0091, Generator_Loss=1.3205\n",
            "Epoch 247: Discriminator_Loss=1.0136, Discriminator_Accuracy=96.9233, Generator_Loss=1.3027\n",
            "Epoch 248: Discriminator_Loss=1.0186, Discriminator_Accuracy=96.9941, Generator_Loss=1.2937\n",
            "Epoch 249: Discriminator_Loss=1.0232, Discriminator_Accuracy=96.9866, Generator_Loss=1.2933\n",
            "Epoch 250: Discriminator_Loss=1.0217, Discriminator_Accuracy=96.9100, Generator_Loss=1.3079\n",
            "Epoch 251: Discriminator_Loss=1.0171, Discriminator_Accuracy=96.9933, Generator_Loss=1.3020\n",
            "Epoch 252: Discriminator_Loss=1.0193, Discriminator_Accuracy=96.8875, Generator_Loss=1.3074\n",
            "Epoch 253: Discriminator_Loss=1.0277, Discriminator_Accuracy=96.9991, Generator_Loss=1.3066\n",
            "Epoch 254: Discriminator_Loss=1.0238, Discriminator_Accuracy=96.8142, Generator_Loss=1.3052\n",
            "Epoch 255: Discriminator_Loss=1.0143, Discriminator_Accuracy=97.0116, Generator_Loss=1.3170\n",
            "Epoch 256: Discriminator_Loss=1.0194, Discriminator_Accuracy=96.9625, Generator_Loss=1.2923\n",
            "Epoch 257: Discriminator_Loss=1.0186, Discriminator_Accuracy=96.8434, Generator_Loss=1.3072\n",
            "Epoch 258: Discriminator_Loss=1.0147, Discriminator_Accuracy=96.8409, Generator_Loss=1.3173\n",
            "Epoch 259: Discriminator_Loss=1.0111, Discriminator_Accuracy=96.8625, Generator_Loss=1.3057\n",
            "Epoch 260: Discriminator_Loss=1.0138, Discriminator_Accuracy=96.9300, Generator_Loss=1.3181\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}